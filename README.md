# Fake News Detection Vulnerability

// enter abstract here

## Goal
Main goal of this work was to train several Natural Language Processing (NLP) models and apply [TextAttack](https://github.com/QData/TextAttack) to detect their vulnerability against Fake News. For our experiments the following models were trained and attacked:
* [BERTweet](https://huggingface.co/vinai/bertweet-base)
* [RoBERTa](https://huggingface.co/roberta-base)
* [Flair Embeddings](https://github.com/flairNLP/flair)
More infomration on the used models, the dataset and the TextAttack recipes can be found in our paper.

## Code and Usage
The `/code` directory includes the `.ipynb` files to train the models and the skeleton to apply TextAttack:
* `TextClassificationModels`
    * Use this notebook to train the models
    * Before running the code you need to choose between binary (only TRUE/FALSE statements) and multi class (all statements) training (set the `binaryClassification` variable to `True`/`False`)
    * In case you choose a model from [Hugging Face](https://huggingface.co/) enter the name of the model in the section **TRAIN HUGGING FACE MODEL**
    * Should you decide to run Flair Embeddings as the NLP model ignore the above mentioned section and run **TRAIN FLAIR EMBEDDING** instead
* `TextAttack`
    * Run this notebook to apply all TextAttack recipes mentioned in our paper
    * The attacks are applied on pre-trained models. If you choose to run the attacks on your own models you will need to upload them to Google Drive and paste the download link into the code.

_The easiest way to run the notebooks without any import issues is through [Google Colab](https://colab.research.google.com/)_
