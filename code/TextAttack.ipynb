{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextAttackSkelleton(False Statements).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Lf4s41fyvytt",
        "_DlAtDq1vytw",
        "YuwcVXikIjIw"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBkbUGcsuQcK"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEIdHJpKtigM",
        "outputId": "faf15362-6694-4cf9-b43b-a796006c8930"
      },
      "source": [
        "!pip install emoji texthero flair gdown textattack"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: texthero in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.7/dist-packages (0.8.0.post1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: textattack in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from texthero) (2.2.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from texthero) (0.22.2.post1)\n",
            "Requirement already satisfied: unidecode>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.2.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.19.5)\n",
            "Requirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.6.0)\n",
            "Requirement already satisfied: plotly>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (4.4.1)\n",
            "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.7/dist-packages (from texthero) (4.41.1)\n",
            "Requirement already satisfied: wordcloud>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.5.0)\n",
            "Requirement already satisfied: nltk>=3.3 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.6.2)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.95)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from flair) (0.0.12)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from flair) (1.5.10)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair) (6.0.3)\n",
            "Requirement already satisfied: torch<=1.7.1,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.1)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3.3)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (from flair) (0.4.1)\n",
            "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.8.1)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.6.5)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.0)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from flair) (1.2.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from textattack) (1.4.1)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from textattack) (3.1.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.7/dist-packages (from textattack) (0.5.10)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from textattack) (8.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from textattack) (3.0.12)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.7/dist-packages (from textattack) (1.1)\n",
            "Requirement already satisfied: lru-dict in /usr/local/lib/python3.7/dist-packages (from textattack) (1.1.7)\n",
            "Requirement already satisfied: bert-score>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from textattack) (0.3.9)\n",
            "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.7/dist-packages (from textattack) (2.5.4)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from textattack) (0.5.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from textattack) (1.7.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from textattack) (1.8.0)\n",
            "Requirement already satisfied: lemminflect in /usr/local/lib/python3.7/dist-packages (from textattack) (0.2.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero) (57.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero) (0.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->texthero) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.2->texthero) (2018.9)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.6.0->texthero) (5.1.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud>=1.5.0->texthero) (7.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->flair) (3.7.4.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->flair) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->flair) (3.10.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.0.45)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (3.13)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.10.3)\n",
            "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words->textattack) (0.6.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->textattack) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->textattack) (0.70.12.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->textattack) (2.0.2)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->textattack) (3.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets->textattack) (2021.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->huggingface-hub->flair) (3.4.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ehjfOavytd"
      },
      "source": [
        "import pandas as pd\n",
        "import re \n",
        "import emoji\n",
        "import texthero as hero\n",
        "from texthero import preprocessing\n",
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "import gdown\n",
        "from textattack.attack_recipes import DeepWordBugGao2018, Pruthi2019, TextBuggerLi2018, PSOZang2020, PWWSRen2019, TextFoolerJin2019, IGAWang2019, BAEGarg2019, CheckList2020\n",
        "from textattack.loggers import CSVLogger\n",
        "from textattack.datasets import Dataset\n",
        "from flair.models import TextClassifier\n",
        "import time\n",
        "from flair.data import Sentence\n",
        "from pandas import DataFrame\n",
        "from textattack.models.wrappers import ModelWrapper\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf4s41fyvytt"
      },
      "source": [
        "# A custom model wrapper \n",
        "* This Class is instantiated with the path to a trained model \n",
        "* An instance of this class can be called with a list of texts and it returns a list of predictions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn5Iqdu-vytv"
      },
      "source": [
        "class CustomModelWrapper(ModelWrapper):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "    \n",
        "    def __call__(self, text_input_list):\n",
        "        df = DataFrame(text_input_list,columns=['claimReview_claimReviewed'])\n",
        "        #df['clean_tweet'] = pipeline(df)\n",
        "        sentences = [Sentence(sentence) for sentence in df['claimReview_claimReviewed'].to_list()]\n",
        "        self.model.predict(sentences, verbose = False, mini_batch_size=32)\n",
        "        predictions=[]\n",
        "        for sentence in sentences:\n",
        "            score = sentence.labels[0].score\n",
        "            if sentence.labels[0].value == 'TRUE':\n",
        "                predictions.append([1-score,score])\n",
        "            else:\n",
        "                predictions.append([score, 1-score])\n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DlAtDq1vytw"
      },
      "source": [
        "# Create a custom_dataset of false claims to be used to attack the trained model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qinnUx1tvytx",
        "outputId": "6865823b-29bf-45e0-d736-cb11aac0341b"
      },
      "source": [
        "custom_dataset = []\n",
        "\n",
        "# download data\n",
        "!wget https://github.com/untruenews/ss2021/raw/main/data/data.csv.zip\n",
        "zf = zipfile.ZipFile(\"data.csv.zip\") \n",
        "\n",
        "# open\n",
        "df_raw = pd.read_csv(zf.open('data_out.csv')).sample(n=3000, random_state=1)\n",
        "df_raw[\"rating_alternateName_normalized\"]=df_raw[\"rating_alternateName_normalized\"].str.upper() #only making sure the labels are normalized.\n",
        "\n",
        "# taking only the english text\n",
        "train_df=df_raw[df_raw.language==\"en\"][[\"claimReview_claimReviewed\",\"rating_alternateName_normalized\"]]\n",
        "\n",
        "for index, row in train_df[train_df['rating_alternateName_normalized']=='FALSE'].iterrows():\n",
        "    custom_dataset.append((row['claimReview_claimReviewed'], 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-27 15:40:26--  https://github.com/untruenews/ss2021/raw/main/data/data.csv.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/untruenews/ss2021/main/data/data.csv.zip [following]\n",
            "--2021-06-27 15:40:26--  https://raw.githubusercontent.com/untruenews/ss2021/main/data/data.csv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85485669 (82M) [application/zip]\n",
            "Saving to: ‘data.csv.zip.2’\n",
            "\n",
            "data.csv.zip.2      100%[===================>]  81.53M   107MB/s    in 0.8s    \n",
            "\n",
            "2021-06-27 15:40:28 (107 MB/s) - ‘data.csv.zip.2’ saved [85485669/85485669]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning:\n",
            "\n",
            "Columns (27) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K3BTxXcS5m1"
      },
      "source": [
        "custom_dataset= random.sample(custom_dataset,40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuwcVXikIjIw"
      },
      "source": [
        "# Save your results to google drive\n",
        "\n",
        "Please add link to trello so the others can access your results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NthcMxTKItgN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b58c255-61b9-4b7a-fc4c-b1d7c330b269"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir \"/content/drive/MyDrive/text-attack-results\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/text-attack-results’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKhJQP2wQpYS"
      },
      "source": [
        "# Load Pretrained Models & Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBCUamaevyty",
        "outputId": "2bde1f75-3d8a-4fa6-b1ce-9e0dacdd9e65"
      },
      "source": [
        "recipes= ['DeepWordBugGao2018','Pruthi2019','TextBuggerLi2018','PSOZang2020', 'PWWSRen2019','TextFoolerJin2019','IGAWang2019','BAEGarg2019','CheckList2020']\n",
        "models = ['flair','berttweet','roberta']\n",
        "\n",
        "\n",
        "for model_name in models:\n",
        "  for recipe in recipes:\n",
        "    print(recipe)\n",
        "    print(model_name)\n",
        "\n",
        "    recept_name = recipe\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    result_dir = \"/content/drive/MyDrive/text-attack-results-false/results-\" + recept_name +\"-\" + timestr\n",
        "    os.mkdir(result_dir)\n",
        "\n",
        "    \n",
        "\n",
        "    if model_name == 'flair':\n",
        "      url = 'https://drive.google.com/uc?id=1xh7O-Wl4Rwr-eau1OrBQRCRXvZ6Z31J4' \n",
        "    elif model_name == 'berttweet':\n",
        "      url = 'https://drive.google.com/uc?id=1m1Zqif7HH4alCoEPBKwXk-9gXXuP0mDh' \n",
        "    else:\n",
        "      url = 'https://drive.google.com/uc?id=1-ouVsPHfIM7pscfguU_upcjZao55A02S' \n",
        "    output = 'best-model.pt' \n",
        "    gdown.download(url, output, quiet = True)\n",
        "\n",
        "    model = TextClassifier.load('./best-model.pt') \n",
        "    model_wrapper = CustomModelWrapper(model)\n",
        "\n",
        "    if recipe == 'DeepWordBugGao2018':  \n",
        "      attack =  DeepWordBugGao2018.build(model_wrapper);\n",
        "    elif recipe == 'Pruthi2019':  \n",
        "      attack =  Pruthi2019.build(model_wrapper);\n",
        "    elif recipe == 'TextBuggerLi2018':  \n",
        "      attack =  TextBuggerLi2018.build(model_wrapper);\n",
        "    elif recipe == 'PSOZang2020':  \n",
        "      attack =  PSOZang2020.build(model_wrapper);\n",
        "    elif recipe == 'PWWSRen2019':  \n",
        "      attack =  PWWSRen2019.build(model_wrapper);\n",
        "    elif recipe == 'TextFoolerJin2019':  \n",
        "      attack =  TextFoolerJin2019.build(model_wrapper);\n",
        "    elif recipe == 'IGAWang2019':  \n",
        "      attack =  IGAWang2019.build(model_wrapper);\n",
        "    elif recipe == 'BAEGarg2019':  \n",
        "      attack =  BAEGarg2019.build(model_wrapper);\n",
        "    elif recipe == 'CheckList2020':  \n",
        "      attack =  CheckList2020.build(model_wrapper);\n",
        "    \n",
        "    dataset = Dataset(custom_dataset)\n",
        "\n",
        "    # Add timestamp to result file\n",
        "    logger = CSVLogger(color_method='html', filename=result_dir+'/results-'+model_name+'.csv')\n",
        "\n",
        "    for example, label in custom_dataset:\n",
        "      result = attack.attack(example, label)\n",
        "      logger.log_attack_result(result)\n",
        "      print(result.__str__(color_method='ansi'))\n",
        "\n",
        "    # Write the result csv to google drive\n",
        "    logger.flush()\n",
        "    summary = logger.df['result_type'].value_counts()\n",
        "    summary.to_csv(result_dir+'/summary-'+model_name+'.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BAEGarg2019\n",
            "berttweet\n",
            "2021-06-27 15:40:54,305 loading file ./best-model.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "textattack: Unknown if model of class <class 'flair.models.text_classification_model.TextClassifier'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "textattack: Logging to CSV at path /content/drive/MyDrive/text-attack-results-false/results-BAEGarg2019-20210627-154048/results-berttweet.csv\n",
            "Using /tmp/tfhub_modules to cache modules.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Trump's Pants on \u001b[91mFire\u001b[0m for claiming 'serious voter \u001b[91mfraud'\u001b[0m occurred in Virginia\n",
            "\n",
            "Trump's Pants on \u001b[92mstood\u001b[0m for claiming 'serious voter \u001b[92mturnout\u001b[0m occurred in Virginia\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (60%)\u001b[0m\n",
            "\n",
            "A reporter who was found dead mailed her lawyer a recording “to be played if anything \u001b[91mhappens\u001b[0m to her.\"\n",
            "\n",
            "A reporter who was found dead mailed her lawyer a recording “to be played if anything \u001b[92mrelates\u001b[0m to her.\"\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Kevin Cramer \u001b[91mdistorts\u001b[0m Heidi Heitkamp's record on banking regulations\n",
            "\n",
            "Kevin Cramer \u001b[92mnoted\u001b[0m Heidi Heitkamp's record on banking regulations\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Newly installed U.S. Secretary of Education Betsy DeVos stipulated that \"all history books will contain only the information that can also be found in the Christian Bible.\"\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Bloggers say Gov. Scott Walker is taking a pay raise while freezing salaries for state employees \n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (97%)\u001b[0m\n",
            "\n",
            "Gingrich claims Obama's \u001b[91morder\u001b[0m will let Interpol investigate American officials\n",
            "\n",
            "Gingrich claims Obama's \u001b[92mpromise\u001b[0m will let Interpol investigate American officials\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (91%)\u001b[0m\n",
            "\n",
            "Florida \u001b[91mmother\u001b[0m who saved her son from an alligator\n",
            "\n",
            "Florida \u001b[92mis\u001b[0m who saved her son from an alligator\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Health care reform will not \u001b[91mforce\u001b[0m \u001b[91mpeople\u001b[0m into a \u001b[91mgovernment-run\u001b[0m plan\n",
            "\n",
            "Health care reform will not \u001b[92mprocess\u001b[0m \u001b[92mcoverage\u001b[0m into a \u001b[92mcontinuous\u001b[0m plan\n",
            "\u001b[91m0 (97%)\u001b[0m --> \u001b[92m1 (69%)\u001b[0m\n",
            "\n",
            "Ann Coulter says Rhode Island was one of first \u001b[91mstates\u001b[0m to pass Voter ID law\n",
            "\n",
            "Ann Coulter says Rhode Island was one of first \u001b[92mstate\u001b[0m to pass Voter ID law\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Gatlinburg, Tennessee \u001b[91mOverrun\u001b[0m by Immigrants\n",
            "\n",
            "Gatlinburg, Tennessee \u001b[92mspoken\u001b[0m by Immigrants\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Rob \u001b[91mZombie\u001b[0m was kicked out of the 88th \u001b[91mAcademy\u001b[0m Awards.\n",
            "\n",
            "Rob \u001b[92mmorrow\u001b[0m was kicked out of the 88th \u001b[92mcommunity\u001b[0m Awards.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (76%)\u001b[0m\n",
            "\n",
            "In August 2017, Harvard University reversed its suspension of Malia \u001b[91mObama\u001b[0m, after an intervention by Barack Obama.\n",
            "\n",
            "In August 2017, Harvard University reversed its suspension of Malia \u001b[92mcourse\u001b[0m, after an intervention by Barack Obama.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Donald Trump has no 'fiduciary \u001b[91mresponsibility'\u001b[0m on his personal \u001b[91mtax\u001b[0m \u001b[91mreturns\u001b[0m, experts say\n",
            "\n",
            "Donald Trump has no 'fiduciary \u001b[92mleft\u001b[0m on his personal \u001b[92mmedia\u001b[0m \u001b[92mbases\u001b[0m, experts say\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Paris-vaccination \u001b[91mconspiracy\u001b[0m \u001b[91mmissing\u001b[0m facts\n",
            "\n",
            "Paris-vaccination \u001b[92ms\u001b[0m \u001b[92mwar\u001b[0m facts\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Does S. Africa really employ more civil servants than the US? The claim is \u001b[91mfalse\u001b[0m | Africa Check\n",
            "\n",
            "Does S. Africa really employ more civil servants than the US? The claim is \u001b[92mtrue\u001b[0m | Africa Check\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Turmeric can prevent dementia; as a result, India, whose food contains a large amount of the spice, has the lowest rates of dementia worldwide.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Websites offer \u001b[91mfalse\u001b[0m headlines about treason 'charges' for Trump, Comey, others\n",
            "\n",
            "Websites offer \u001b[92mhigh\u001b[0m headlines about treason 'charges' for Trump, Comey, others\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "No evidence for Trump claim that it was 'impossible' for Syrian Christians to enter U.S.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (99%)\u001b[0m\n",
            "\n",
            "Mitt Romney says Obama's Chrysler deal \u001b[91mundermined\u001b[0m U.S. workers\n",
            "\n",
            "Mitt Romney says Obama's Chrysler deal \u001b[92minterests\u001b[0m U.S. workers\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Uniformed police officers were not allowed on the \u001b[91mfloor\u001b[0m at the Democratic National Convention.\n",
            "\n",
            "Uniformed police officers were not allowed on the \u001b[92mavenue\u001b[0m at the Democratic National Convention.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (99%)\u001b[0m\n",
            "\n",
            "Willie \u001b[91mNelson\u001b[0m \u001b[91mfell\u001b[0m \u001b[91mseriously\u001b[0m ill in May 2018.\n",
            "\n",
            "Willie \u001b[92mcampbell\u001b[0m \u001b[92mfallen\u001b[0m \u001b[92mtemporarily\u001b[0m ill in May 2018.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "State Sen. Mike Doherty claims financial collapse \u001b[91mled\u001b[0m to no \u001b[91mprosecutions\u001b[0m, hearings or reforms\n",
            "\n",
            "State Sen. Mike Doherty claims financial collapse \u001b[92mcompared\u001b[0m to no \u001b[92mconference\u001b[0m, hearings or reforms\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (95%)\u001b[0m\n",
            "\n",
            "U.S. Chamber tells seniors that 20 million could \u001b[91mlose\u001b[0m coverage under the health care law\n",
            "\n",
            "U.S. Chamber tells seniors that 20 million could \u001b[92mget\u001b[0m coverage under the health care law\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Scott Walker \u001b[91msays\u001b[0m Mark Neumann = \u001b[91mNancy\u001b[0m Pelosi\n",
            "\n",
            "Scott Walker [\u001b[92mUNK\u001b[0m] Mark Neumann = \u001b[92mhip\u001b[0m Pelosi\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Have Senate Republicans filibustered every nominee end every piece of legislation under President Barack Obama?\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "\n",
            "Recent Study Shows How Sunscreen Causes \u001b[91mCancer\u001b[0m, \u001b[91mNot\u001b[0m the Sun \n",
            "\n",
            "\n",
            "Recent Study Shows How Sunscreen Causes \u001b[92mdiscomfort\u001b[0m, \u001b[92meven\u001b[0m the Sun \n",
            "\u001b[91m0 (98%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Republican VP candidate Mike Pence  proclaimedthat \"the things Donald Trump says wouldn't \u001b[91mhurt\u001b[0m our campaign half as much if the press didn't report it.\"\n",
            "\n",
            "Republican VP candidate Mike Pence  proclaimedthat \"the things Donald Trump says wouldn't \u001b[92mmake\u001b[0m our campaign half as much if the press didn't report it.\"\n",
            "\u001b[91m0 (99%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Arab Gas Station Attendant \u001b[91mRefused\u001b[0m Service to U.S. Soldier in Michigan\n",
            "\n",
            "Arab Gas Station Attendant \u001b[92mcustomer\u001b[0m Service to U.S. Soldier in Michigan\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "No, SA government didn't order power utility Eskom to lay off white workers | Africa Check\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "The McDonald's fast food chain has implemented a policy barring their customers from buying food for homeless people.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "David Dewhurst says under Texas law, it takes six years to close a failing school\n",
            "\u001b[92m1 (83%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "Africa's 'Bono' claims that music is one of Africa's biggest exports\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "An investigation has proven the \u001b[91mpresence\u001b[0m of \u001b[91mfeces\u001b[0m in Starbucks beverages.\n",
            "\n",
            "An investigation has proven the \u001b[92msuccess\u001b[0m of \u001b[92mace\u001b[0m in Starbucks beverages.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Elizabeth Warren: Women Need to Be \u001b[91mRaped\u001b[0m by Muslims to Prove Tolerance\n",
            "\n",
            "Elizabeth Warren: Women Need to Be \u001b[92munderstood\u001b[0m by Muslims to Prove Tolerance\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "A fake news article reported that a cross-eyed woman cut off her partner's penis after he refused to look her in the eye during sex.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Bruce Springsteen called Donald Trump an \"asshole\" on Twitter, signing off with the pro-Clinton hashtag #ImWithHer.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Donald Trump falls for phony Gandhi quote: 'First they ignore you, then they laugh at you ... '\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "Talk show \u001b[91mhost\u001b[0m \u001b[91mOprah\u001b[0m Winfrey is pregnant with her first child at 61.\n",
            "\n",
            "Talk show \u001b[92mveteran\u001b[0m \u001b[92mwins\u001b[0m Winfrey is pregnant with her first child at 61.\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "7,000 millionaires \"gamed the system\" to pay zero federal income taxes, U.S. Senate candidate Tammy Baldwin says\n",
            "\u001b[91m0 (100%)\u001b[0m --> \u001b[92m1 (100%)\u001b[0m\n",
            "\n",
            "A photograph \u001b[91mshows\u001b[0m \u001b[91mDonald\u001b[0m \u001b[91mTrump\u001b[0m in a diaper.\n",
            "\n",
            "A photograph \u001b[92mincluded\u001b[0m \u001b[92msenator\u001b[0m \u001b[92mwalsh\u001b[0m in a diaper.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnr5dC8Cvytz"
      },
      "source": [
        "# Attack results \n",
        "* `logger.df` is a dataframe that has all the results of the attack\n",
        "* The results can be either `Successful`, `Failed` or `Skipped`\n",
        "* An attack is skipped when the original text is missclassified by the model and therefore the text won't be used to attack the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNQNsigivyt0"
      },
      "source": [
        "logger.df['result_type'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzt6PeSU3lnO"
      },
      "source": [
        ""
      ]
    }
  ]
}